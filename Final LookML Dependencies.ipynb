{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Dependencies for LookML Dimensions and Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the script, follow the instructions at https://github.com/llooker/python_api_samples to configure a config file and save it in your working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import yaml \n",
    "from lookerapi import LookerApi\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to your Looker Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assumes that you the config.yml in current directory\n",
    "def connect_looker():\n",
    "    global looker \n",
    "    \n",
    "    #get credentials\n",
    "    f = open('config.yml')\n",
    "    params = yaml.load(f)\n",
    "    host = 'localhost'\n",
    "    f.close()\n",
    "    my_host = params['hosts'][host]['host']\n",
    "    my_secret = params['hosts'][host]['secret']\n",
    "    my_token = params['hosts'][host]['token']\n",
    "    \n",
    "    #connect to Looker\n",
    "    looker = LookerApi(host=my_host,\n",
    "    token=my_token,\n",
    "    secret = my_secret)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to combine two dictionaries in a way that does not override and eliminates duplicate values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dictionaries(dict1,dict2,data_type):\n",
    "    if data_type != 'dependencies':\n",
    "        dict1.update(dict2)\n",
    "    else:\n",
    "        for key in dict2.keys():\n",
    "            if key in dict1.keys():\n",
    "                values = dict1[key]\n",
    "                values = list(set(values + dict2[key]))\n",
    "                dict1[key] = values\n",
    "            else:\n",
    "                dict1[key] = dict2[key]\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create dictionaries of Looker objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User enters the model_name and the explore_name. If data_type is 'sql' then the resulting dictionary will have dimension/measure names as keys and sql statements as values, if data_type is 'lookml_link' then the dictionaries values will be links to the line of the metric in the view file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionaries(model_name,explore_name,data_type='sql'):\n",
    "    global explore\n",
    "    explore = looker.get_explore(explore_name=explore_name,model_name=model_name)\n",
    "    dimensions = explore['fields']['dimensions']\n",
    "    measures = explore['fields']['measures']\n",
    "    field_dict = dict()\n",
    "    for dimension in dimensions:\n",
    "        field_dict[dimension['name']] = dimension[data_type]\n",
    "    for measure in measures:\n",
    "        field_dict[measure['name']] = measure[data_type]\n",
    "    return field_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each metric in the explore environment, look at the sql values for every other metric to see if the original one is in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data(model_name,explore_name = None,data_type = 'dependencies'):\n",
    "    global field_dict\n",
    "    if explore_name is not None:\n",
    "        data = dict()\n",
    "        if data_type == 'dependencies':\n",
    "            field_dict = create_dictionaries(model_name,explore_name)\n",
    "            for metric in field_dict:\n",
    "                for other_metric in field_dict:\n",
    "                    if '${' + metric + '}' in field_dict[other_metric] or \\\n",
    "                        ('${' + metric.split('.')[1] + '}' in field_dict[other_metric] \\\n",
    "                         and metric.split('.')[0] == other_metric.split('.')[0]):\n",
    "                        if metric in data.keys():\n",
    "                            data[metric].append(other_metric)\n",
    "                        else:\n",
    "                            data[metric] = [other_metric]\n",
    "                if metric not in data.keys():\n",
    "                    data[metric] = [np.nan]\n",
    "        elif data_type != ' dependencies':\n",
    "            data = create_dictionaries(model_name,explore_name,data_type=data_type)\n",
    "    else: \n",
    "        global model\n",
    "        model = looker.get_model(model_name)\n",
    "        data = dict()\n",
    "        for explore in model['explores']:\n",
    "            data = update_dictionaries(data,compile_data(model_name,explore['name'],data_type),data_type)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(dictionary):\n",
    "    df = pd.DataFrame.from_dict(dictionary,orient='index').reset_index()\n",
    "    df = pd.melt(df,id_vars=['index'],value_vars=list(range(0,len(df.columns)))).drop(columns='variable')\n",
    "    return df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataframe that has the Metric, and the Dependency that is dependent on that metric, as well as the links to both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(model_name,explore_name=None):\n",
    "    global dependencies,link_dict,link_df\n",
    "    dependencies = compile_data(model_name,explore_name)\n",
    "    df = transform_df(dependencies)\n",
    "    \n",
    "    df.columns = ['Metric','Dependency']\n",
    "    \n",
    "    link_dict = compile_data(model_name,explore_name,data_type='lookml_link')\n",
    "    link_df = transform_df(link_dict)\n",
    "    link_df.columns = ['Metric','Link']\n",
    "    \n",
    "    df = pd.merge(df,link_df.dropna(),on='Metric',how='left')\n",
    "    df = pd.merge(df,link_df.dropna(),left_on='Dependency',right_on='Metric',how='left')\n",
    "    df = df.drop(columns='Metric_y')\n",
    "    df.columns = ['Metric','Dependency','Metric Link','Dependency Link']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the program with User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    connect_looker()\n",
    "    model_name = None\n",
    "    models = looker.get_models()\n",
    "    model_names = []\n",
    "    for i in models:\n",
    "        model_names.append(i['name'])\n",
    "    while model_name not in model_names:\n",
    "        print('Enter the model name:')\n",
    "        model_name = input()\n",
    "        if model_name not in model_names:\n",
    "            print('Incorrect model name, please enter one of the following names:')\n",
    "            print(' , '.join(model_names))\n",
    "\n",
    "    model = looker.get_model(model_name)    \n",
    "    explores = model['explores']\n",
    "    explore_names = []\n",
    "    for i in explores:\n",
    "        explore_names.append(i['name'])\n",
    "    explore_name = None\n",
    "    while explore_name not in explore_names and explore_name != 'All':\n",
    "        print('Enter the explore name, or enter \"All\"')\n",
    "        explore_name = input()\n",
    "        if explore_name not in explore_names and explore_name != 'All':\n",
    "            print('Incorrect explore name, please enter one of the following names or \"All\":')\n",
    "            print(' , '.join(explore_names))\n",
    "    if explore_name == 'All':\n",
    "        explore_name = None\n",
    "\n",
    "    df = create_df(model_name,explore_name)\n",
    "    df.to_csv(model_name+'_dependencies.csv')\n",
    "    print('Finished! Check out the file: ' + model_name +'_dependencies.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the model name:\n",
      "thelook\n",
      "https://demo.looker.com:19999/api/3.1/lookml_models/thelook\n",
      "Enter the explore name, or enter \"All\"\n",
      "order_items\n",
      "Finished! Check out the file: thelook_dependencies.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
